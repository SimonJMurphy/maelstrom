{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.dpi\"] = 150\n",
    "rcParams[\"savefig.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sjm/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kepler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3401eed718d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkepler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkepler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kepler'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kepler import kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kicid = 6862920\n",
    "\n",
    "data = np.loadtxt(\"data/kic{0}_lc.txt\".format(kicid))\n",
    "fulltimes = data[:, 0] # days\n",
    "tmid = 0.5*(fulltimes[0] + fulltimes[-1])\n",
    "times = fulltimes - tmid\n",
    "dmmags = data[:, 1] * 1000. # mmags\n",
    "\n",
    "# times = times[2500:]\n",
    "# dmmags = dmmags[2500:]\n",
    "\n",
    "metadata = np.loadtxt(\"data/kic{0}_metadata.csv\".format(kicid), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(times,dmmags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu_arr = metadata[::6]\n",
    "# m = np.ones_like(nu_arr, dtype=bool)\n",
    "# m[[0, 3, 4, 5]] = False\n",
    "# nu_arr = nu_arr[m]\n",
    "# nu_arr = nu_arr[[0] + list(range(3, len(nu_arr)))]\n",
    "nu_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orbits = pd.read_csv(\"data/orbits.csv\").rename(columns = lambda x: x.strip())\n",
    "orbits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orb_params = orbits[orbits.Name == \"kic{0}\".format(kicid)].iloc[0]\n",
    "porb = orb_params.Porb\n",
    "a1 = orb_params[\"a1sini/c\"]\n",
    "tp = orb_params[\"t_p\"] - tmid\n",
    "e = orb_params[\"e\"]\n",
    "varpi = orb_params[\"varpi\"]\n",
    "a1d = a1/86400.0\n",
    "e_param = np.log(e) - np.log(1.0 - e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where the TensorFlow stuff starts. The \"session\" is the thing that will actually do the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way that TensorFlow works is that you define the operations on `Variable` and `placeholder` objects. Here we describe the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = tf.float64\n",
    "\n",
    "# First the variables that we might want to optimize:\n",
    "porb_tensor = tf.Variable(porb, dtype=T)\n",
    "tp_tensor = tf.Variable(tp, dtype=T)\n",
    "nu_tensor = tf.Variable(nu_arr, dtype=T)\n",
    "e_param_tensor = tf.Variable(e_param, dtype=T)  # This forces the ecc to be between 0 and 1\n",
    "e_tensor = 1.0 / (1.0 + tf.exp(-e_param_tensor))\n",
    "varpi_tensor = tf.Variable(varpi, dtype=T)\n",
    "log_sigma2_tensor = tf.Variable(0.0, dtype=T)  # Variance from observational uncertainties and model misspecification\n",
    "\n",
    "ad_tensor = tf.Variable(a1d + np.zeros_like(nu_arr), dtype=T)\n",
    "\n",
    "# These are some placeholders for the data:\n",
    "times_tensor = tf.placeholder(T, times.shape)\n",
    "dmmags_tensor = tf.placeholder(T, dmmags.shape)\n",
    "\n",
    "# Solve Kepler's equation\n",
    "mean_anom = 2.0 * np.pi * (times_tensor - tp_tensor) / porb_tensor\n",
    "ecc_anom = kepler(mean_anom, e_tensor)\n",
    "true_anom = 2.0 * tf.atan2(tf.sqrt(1.0+e_tensor)*tf.tan(0.5*ecc_anom), tf.sqrt(1.0-e_tensor) + tf.zeros_like(times_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a unit vector to describe the time delay in the tau_tensor, and multiply this by an amplitude scalar which is the semi-major axis, ad_tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we define how the time delay will be calculated:\n",
    "tau_tensor = -(1.0 - tf.square(e_tensor)) * tf.sin(true_anom + varpi_tensor) / (1.0 + e_tensor*tf.cos(true_anom))\n",
    "\n",
    "# And the design matrix:\n",
    "arg_tensor = 2.0 * np.pi * nu_tensor[None, :] * (times_tensor[:, None] - ad_tensor[None, :] * tau_tensor[:, None])\n",
    "D_tensor = tf.concat([tf.cos(arg_tensor), tf.sin(arg_tensor)], axis=1)\n",
    "\n",
    "# Define the linear solve for W_hat:\n",
    "DTD_tensor = tf.matmul(D_tensor, D_tensor, transpose_a=True)\n",
    "DTy_tensor = tf.matmul(D_tensor, dmmags_tensor[:, None], transpose_a=True)\n",
    "W_hat_tensor = tf.linalg.solve(DTD_tensor, DTy_tensor)\n",
    "\n",
    "# Finally, the model and the chi^2 objective:\n",
    "model_tensor = tf.squeeze(tf.matmul(D_tensor, W_hat_tensor))\n",
    "chi2_tensor = tf.reduce_sum(tf.square(dmmags_tensor - model_tensor)) * tf.exp(-log_sigma2_tensor)\n",
    "chi2_tensor += len(times) * log_sigma2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you could evaluate different parts of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to initialize the variables:\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# We'll also need to pass in the data:\n",
    "data = {times_tensor: times, dmmags_tensor: dmmags}\n",
    "\n",
    "# Let's plot the initial time delay\n",
    "initial_tau = sess.run(tau_tensor, feed_dict=data)\n",
    "plt.plot(times+tmid, initial_tau, \".\", ms=2)\n",
    "plt.ylabel(r\"$\\tau(t)$\")\n",
    "plt.xlabel(\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_model = sess.run(model_tensor, feed_dict=data)\n",
    "plt.plot(times, dmmags, \".k\")\n",
    "plt.plot(times, initial_model)\n",
    "# plt.xlim(100, 102)\n",
    "# plt.ylim(-75, 75)\n",
    "plt.xlabel(\"t, days\")\n",
    "plt.ylabel(\"L(t), mmag\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit the parameters. We'll iterate with different subsets a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_chi2 = sess.run(chi2_tensor, feed_dict=data)\n",
    "for i in range(2):\n",
    "    params = [log_sigma2_tensor, porb_tensor, tp_tensor]\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "    \n",
    "    params.append(ad_tensor)\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "\n",
    "    params += [e_param_tensor, varpi_tensor]\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "        \n",
    "    new_chi2 = sess.run(chi2_tensor, feed_dict=data)\n",
    "    print(old_chi2 - new_chi2)\n",
    "    if np.abs(old_chi2 - new_chi2) < 1.0:\n",
    "        break\n",
    "    old_chi2 = new_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the updated final plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_tau = sess.run(tau_tensor, feed_dict=data)\n",
    "plt.plot(times+tmid, initial_tau, \".\", ms=2)\n",
    "plt.plot(times+tmid, final_tau, \".\", ms=2)\n",
    "plt.ylabel(r\"$\\tau(t) / a$\")\n",
    "plt.xlabel(\"$t$, reduced BJD\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = tau_tensor[:, None] * ad_tensor[None, :]\n",
    "plt.plot(times+tmid, sess.run(models, feed_dict=data), \".\", ms=3)\n",
    "plt.ylabel(r\"$\\tau(t)$, days\")\n",
    "plt.xlabel(\"$t$, reduced BJD\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ivar = -np.diag(sess.run(tf.hessians(-0.5*chi2_tensor, ad_tensor), feed_dict=data)[0])\n",
    "ad = sess.run(ad_tensor)\n",
    "ad *= np.sign(ad[0])\n",
    "sig = 1.0 / np.sqrt(ivar)\n",
    "plt.errorbar(np.arange(len(ad)), ad, yerr=sig, fmt=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m = np.ones_like(ad, dtype=bool)\n",
    "# while True:\n",
    "#     var = 1.0 / np.sum(ivar[m])\n",
    "#     mu = np.sum(ivar[m] * ad[m]) * var\n",
    "#     var2 = np.sum(ivar[m] * (mu - ad[m])**2) * var\n",
    "#     m_new = np.abs(ad - mu) / np.sqrt(var) < 7.0\n",
    "#     if m.sum() == m_new.sum():\n",
    "#         m = m_new\n",
    "#         break\n",
    "#     m = m_new\n",
    "# ad = ad[m]\n",
    "# ivar = ivar[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig = 1.0 / np.sqrt(ivar)\n",
    "plt.errorbar(np.arange(len(ad)), ad, yerr=sig, fmt=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if np.any(ad < 0):\n",
    "    m1 = ad > 0\n",
    "    m2 = ad <= 0\n",
    "    ad = [\n",
    "        np.sum(ivar[m1]*ad[m1]) / np.sum(ivar[m1]),\n",
    "        np.sum(ivar[m2]*ad[m2]) / np.sum(ivar[m2]),\n",
    "    ]\n",
    "else:\n",
    "    ad = [np.sum(ivar*ad) / np.sum(ivar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = tf.cast(0.5 - 0.5 * (ad_tensor / tf.abs(ad_tensor)), tf.int32)\n",
    "ad_params = tf.Variable(ad, dtype=T)\n",
    "sess.run(ad_params.initializer)\n",
    "ad_tensor = tf.gather(ad_params, inds)\n",
    "\n",
    "# And the design matrix:\n",
    "arg_tensor = 2.0 * np.pi * nu_tensor[None, :] * (times_tensor[:, None] - ad_tensor[None, :] * tau_tensor[:, None])\n",
    "D_tensor = tf.concat([tf.cos(arg_tensor), tf.sin(arg_tensor)], axis=1)\n",
    "\n",
    "# Define the linear solve for W_hat:\n",
    "DTD_tensor = tf.matmul(D_tensor, D_tensor, transpose_a=True)\n",
    "DTy_tensor = tf.matmul(D_tensor, dmmags_tensor[:, None], transpose_a=True)\n",
    "W_hat_tensor = tf.linalg.solve(DTD_tensor, DTy_tensor)\n",
    "\n",
    "# Finally, the model and the chi^2 objective:\n",
    "model_tensor = tf.squeeze(tf.matmul(D_tensor, W_hat_tensor))\n",
    "chi2_tensor = tf.reduce_sum(tf.square(dmmags_tensor - model_tensor)) * tf.exp(-log_sigma2_tensor)\n",
    "chi2_tensor += len(times) * log_sigma2_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_chi2 = sess.run(chi2_tensor, feed_dict=data)\n",
    "for i in range(5):\n",
    "    params = [log_sigma2_tensor, porb_tensor, tp_tensor]\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "    \n",
    "    params.append(ad_params)\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "\n",
    "    params += [e_param_tensor, varpi_tensor]\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "    \n",
    "    params.append(nu_tensor)\n",
    "    opt = tf.contrib.opt.ScipyOptimizerInterface(chi2_tensor, params, method=\"L-BFGS-B\")\n",
    "    opt.minimize(sess, feed_dict=data)\n",
    "    \n",
    "    new_chi2 = sess.run(chi2_tensor, feed_dict=data)\n",
    "    print(old_chi2 - new_chi2)\n",
    "    if np.abs(old_chi2 - new_chi2) < 1.0:\n",
    "        break\n",
    "    old_chi2 = new_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = tau_tensor[:, None] * ad_tensor[None, :]\n",
    "plt.plot(times+tmid, 86400.0 * sess.run(models, feed_dict=data), \".\", ms=2);\n",
    "plt.ylabel(r\"$\\tau(t)$\")\n",
    "plt.xlabel(\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(e_tensor), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hess_tensor = tf.hessians(-0.5*chi2_tensor, params[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hess = sess.run(hess_tensor, feed_dict=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. / np.sqrt(-hess[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-np.diag(np.linalg.inv(hess[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(ad_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
